# CSS ç±»ååŠ©æ‰‹ - å¾®è°ƒæŒ‡å—

## ğŸ“‹ å‡†å¤‡å·¥ä½œå·²å®Œæˆ

âœ… LLaMA-Factory å·²å®‰è£…  
âœ… è®­ç»ƒæ•°æ®å·²å‡†å¤‡ (10,406 æ¡)  
âœ… é…ç½®æ–‡ä»¶å·²åˆ›å»º  
âœ… è™šæ‹Ÿç¯å¢ƒå·²é…ç½®  

---

## ğŸš€ å¼€å§‹å¾®è°ƒï¼ˆä¸¤ç§æ–¹å¼ï¼‰

### æ–¹å¼ 1ï¼šWeb UIï¼ˆæ¨èï¼Œé›¶ä»£ç ï¼‰

```bash
cd /Users/songyanchao/Desktop/thing/zhishi/finetune/LLaMA-Factory
source ../llama_env/bin/activate
python3 src/webui.py
```

ç„¶åæµè§ˆå™¨æ‰“å¼€ `http://127.0.0.1:7860`

**Web UI æ“ä½œæ­¥éª¤**ï¼š
1. **æ¨¡å‹åç§°**: è¾“å…¥ `Qwen/Qwen2.5-3B-Instruct`
2. **æ•°æ®é›†**: é€‰æ‹© `css_assistant`
3. **å¾®è°ƒæ–¹æ³•**: é€‰æ‹© `LoRA`
4. **LoRA ç§©**: è®¾ç½®ä¸º `8`
5. **å­¦ä¹ ç‡**: è®¾ç½®ä¸º `5e-5`
6. **è®­ç»ƒè½®æ•°**: è®¾ç½®ä¸º `3`
7. **æ‰¹æ¬¡å¤§å°**: è®¾ç½®ä¸º `2`
8. ç‚¹å‡» **å¼€å§‹è®­ç»ƒ**

---

### æ–¹å¼ 2ï¼šå‘½ä»¤è¡Œï¼ˆè‡ªåŠ¨åŒ–ï¼‰

```bash
cd /Users/songyanchao/Desktop/thing/zhishi/finetune
source llama_env/bin/activate
python3 train_cli.py
```

---

## â±ï¸ é¢„è®¡è®­ç»ƒæ—¶é—´

- **M1 Pro (32GB)**: çº¦ 2-4 å°æ—¶
- **æ•°æ®é‡**: 10,406 æ¡
- **è®­ç»ƒè½®æ•°**: 3 epochs
- **æ˜¾å­˜å ç”¨**: çº¦ 8-12GB

---

## ğŸ“Š è®­ç»ƒè¿‡ç¨‹ç›‘æ§

è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šæ˜¾ç¤ºï¼š
- âœ… Lossï¼ˆæŸå¤±å€¼ï¼‰- è¶Šä½è¶Šå¥½
- âœ… Learning Rateï¼ˆå­¦ä¹ ç‡ï¼‰
- âœ… Steps/Secondï¼ˆè®­ç»ƒé€Ÿåº¦ï¼‰
- âœ… ETAï¼ˆé¢„è®¡å‰©ä½™æ—¶é—´ï¼‰

**æ­£å¸¸ç°è±¡**ï¼š
- Loss ä» 2-3 é€æ¸é™åˆ° 0.5 ä»¥ä¸‹
- å‰å‡ ç™¾æ­¥å¯èƒ½è¾ƒæ…¢ï¼ˆæ¨¡å‹ä¸‹è½½å’Œåˆå§‹åŒ–ï¼‰

---

## ğŸ’¾ è®­ç»ƒå®Œæˆå

æ¨¡å‹ä¿å­˜åœ¨ï¼š
```
/Users/songyanchao/Desktop/thing/zhishi/finetune/output_model/
```

åŒ…å«æ–‡ä»¶ï¼š
- `adapter_config.json` - LoRA é…ç½®
- `adapter_model.safetensors` - LoRA æƒé‡
- `tokenizer_config.json` - åˆ†è¯å™¨é…ç½®
- `training_args.bin` - è®­ç»ƒå‚æ•°

---

## ğŸ§ª æµ‹è¯•å¾®è°ƒåçš„æ¨¡å‹

### æ–¹æ³• 1ï¼šä½¿ç”¨ LLaMA-Factory çš„ Chat UI

```bash
cd /Users/songyanchao/Desktop/thing/zhishi/finetune/LLaMA-Factory
source ../llama_env/bin/activate
python3 src/webui.py
```

åœ¨ Web UI ä¸­ï¼š
1. åˆ‡æ¢åˆ° **Chat** æ ‡ç­¾é¡µ
2. åŠ è½½åŸºåº§æ¨¡å‹ï¼š`Qwen/Qwen2.5-3B-Instruct`
3. åŠ è½½ LoRA é€‚é…å™¨ï¼šé€‰æ‹©ä½ çš„è¾“å‡ºç›®å½•
4. å¼€å§‹å¯¹è¯æµ‹è¯•

### æ–¹æ³• 2ï¼šPython è„šæœ¬æµ‹è¯•

åˆ›å»ºæµ‹è¯•è„šæœ¬ `test_model.py`ï¼š

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
from peft import PeftModel

# åŠ è½½åŸºåº§æ¨¡å‹
base_model = AutoModelForCausalLM.from_pretrained(
    "Qwen/Qwen2.5-3B-Instruct",
    trust_remote_code=True,
    device_map="auto"
)

# åŠ è½½ LoRA é€‚é…å™¨
model = PeftModel.from_pretrained(
    base_model,
    "/Users/songyanchao/Desktop/thing/zhishi/finetune/output_model"
)

# åŠ è½½åˆ†è¯å™¨
tokenizer = AutoTokenizer.from_pretrained(
    "Qwen/Qwen2.5-3B-Instruct",
    trust_remote_code=True
)

# æµ‹è¯•
def chat(query):
    messages = [{"role": "user", "content": query}]
    text = tokenizer.apply_chat_template(
        messages,
        tokenize=False,
        add_generation_prompt=True
    )
    inputs = tokenizer([text], return_tensors="pt").to(model.device)
    outputs = model.generate(**inputs, max_new_tokens=128)
    response = tokenizer.decode(outputs[0], skip_special_tokens=True)
    return response.split("assistant\n")[-1]

# æµ‹è¯•ç”¨ä¾‹
print("æµ‹è¯• 1:", chat("æˆ‘éœ€è¦ä¸€ä¸ªçº¢è‰²èƒŒæ™¯"))
print("æµ‹è¯• 2:", chat("è®¾ç½®åœ†è§’"))
print("æµ‹è¯• 3:", chat("ç”Ÿæˆä¸€ä¸ªé€æ˜èƒŒæ™¯çš„div"))
```

---

## ğŸ¯ é¢„æœŸæ•ˆæœ

è®­ç»ƒæˆåŠŸåï¼Œæ¨¡å‹åº”è¯¥èƒ½å¤Ÿï¼š

âœ… **è¾“å…¥**: "æˆ‘éœ€è¦ä¸€ä¸ªçº¢è‰²èƒŒæ™¯"  
âœ… **è¾“å‡º**: `bg-red`

âœ… **è¾“å…¥**: "è®¾ç½®åœ†è§’"  
âœ… **è¾“å‡º**: `radius-xxx`

âœ… **è¾“å…¥**: "ç”Ÿæˆä¸€ä¸ªé€æ˜èƒŒæ™¯çš„div"  
âœ… **è¾“å‡º**: `<div className="bg-c-transparent">å†…å®¹</div>`

âœ… **è¾“å…¥**: "ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"  
âœ… **è¾“å‡º**: "æŠ±æ­‰ï¼Œæˆ‘æ˜¯CSSç±»ååŠ©æ‰‹ï¼Œåªèƒ½å›ç­”CSSç›¸å…³çš„é—®é¢˜..."

---

## â“ å¸¸è§é—®é¢˜

### Q1: æ˜¾å­˜ä¸è¶³æ€ä¹ˆåŠï¼Ÿ
**A**: å‡å°æ‰¹æ¬¡å¤§å°ï¼š
```yaml
per_device_train_batch_size: 1  # ä» 2 æ”¹ä¸º 1
gradient_accumulation_steps: 8  # ä» 4 æ”¹ä¸º 8
```

### Q2: è®­ç»ƒå¤ªæ…¢æ€ä¹ˆåŠï¼Ÿ
**A**: å‡å°‘æ•°æ®é‡æˆ–è®­ç»ƒè½®æ•°ï¼š
```yaml
max_samples: 5000  # åªç”¨ä¸€åŠæ•°æ®
num_train_epochs: 2  # ä» 3 æ”¹ä¸º 2
```

### Q3: å¦‚ä½•ç»§ç»­è®­ç»ƒï¼Ÿ
**A**: è®¾ç½® `resume_from_checkpoint`:
```yaml
resume_from_checkpoint: /path/to/checkpoint-500
```

### Q4: å¦‚ä½•éƒ¨ç½²æ¨¡å‹ï¼Ÿ
**A**: åˆå¹¶ LoRA æƒé‡åˆ°åŸºåº§æ¨¡å‹ï¼š
```bash
python3 src/export_model.py \
    --model_name_or_path Qwen/Qwen2.5-3B-Instruct \
    --adapter_name_or_path ./output_model \
    --export_dir ./merged_model \
    --export_size 2
```

---

## ğŸ“ éœ€è¦å¸®åŠ©ï¼Ÿ

å¦‚æœé‡åˆ°é—®é¢˜ï¼Œè¯·æ£€æŸ¥ï¼š
1. è™šæ‹Ÿç¯å¢ƒæ˜¯å¦æ¿€æ´»
2. æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
3. æ˜¾å­˜æ˜¯å¦å……è¶³
4. ç½‘ç»œæ˜¯å¦æ­£å¸¸ï¼ˆé¦–æ¬¡éœ€è¦ä¸‹è½½æ¨¡å‹ï¼‰

---

## ğŸ‰ ä¸‹ä¸€æ­¥

è®­ç»ƒå®Œæˆåï¼Œä½ å¯ä»¥ï¼š
1. éƒ¨ç½²ä¸º API æœåŠ¡
2. é›†æˆåˆ° VSCode æ’ä»¶
3. ç»§ç»­å¾®è°ƒä¼˜åŒ–
4. å°è¯•æ›´å¤§çš„æ¨¡å‹ï¼ˆ7Bï¼‰

ç¥è®­ç»ƒé¡ºåˆ©ï¼ğŸš€
