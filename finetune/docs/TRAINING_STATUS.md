# CSS åŠ©æ‰‹æ¨¡å‹å¾®è°ƒ - è®­ç»ƒçŠ¶æ€

## ğŸ“Š å½“å‰çŠ¶æ€

**è®­ç»ƒå·²å¯åŠ¨ï¼** âœ…

- **å¼€å§‹æ—¶é—´**: 2025-11-11 10:31 AM
- **è®­ç»ƒè¿›ç¨‹**: æ­£åœ¨è¿è¡Œ
- **åŸºåº§æ¨¡å‹**: Qwen/Qwen2.5-3B-Instruct (3.09B å‚æ•°)
- **å¾®è°ƒæ–¹æ³•**: LoRA (QLoRA)
- **å¯è®­ç»ƒå‚æ•°**: 14,966,784 (0.48%)

## ğŸ“ˆ è®­ç»ƒé…ç½®

### æ•°æ®é›†
- **è®­ç»ƒæ ·æœ¬æ•°**: 10,406 æ¡
- **æ•°æ®æ–‡ä»¶**: `training_data.json`
- **æ•°æ®è´¨é‡**: 
  - æ­£æ ·æœ¬: 9,585 æ¡ (92.1%)
  - è´Ÿæ ·æœ¬: 821 æ¡ (7.9%)

### è®­ç»ƒå‚æ•°
- **æ‰¹æ¬¡å¤§å°**: 4
- **æ¢¯åº¦ç´¯ç§¯æ­¥æ•°**: 4
- **æœ‰æ•ˆæ‰¹æ¬¡å¤§å°**: 16
- **å­¦ä¹ ç‡**: 2e-4
- **è®­ç»ƒè½®æ•°**: 3
- **æœ€å¤§åºåˆ—é•¿åº¦**: 512
- **ä¼˜åŒ–å™¨**: AdamW
- **å­¦ä¹ ç‡è°ƒåº¦**: Cosine

### LoRA é…ç½®
- **ç§© (r)**: 8
- **Alpha**: 16
- **Dropout**: 0.05
- **ç›®æ ‡æ¨¡å—**: q_proj, k_proj, v_proj, o_proj, gate_proj, up_proj, down_proj

## ğŸ” ç›‘æ§è®­ç»ƒ

### æŸ¥çœ‹è®­ç»ƒçŠ¶æ€
```bash
cd /Users/songyanchao/Desktop/thing/zhishi/finetune
./monitor_training.sh
```

### æš‚åœè®­ç»ƒ
```bash
./pause_training.sh
```
**è¯´æ˜**: 
- ä¼šå‘é€ä¸­æ–­ä¿¡å·å®‰å…¨åœæ­¢è®­ç»ƒ
- å¦‚æœè®­ç»ƒå·²ä¿å­˜ checkpointï¼Œå¯ä»¥ç¨åæ¢å¤
- å¦‚æœæœªåˆ°ä¿å­˜ç‚¹ï¼ˆ500æ­¥ï¼‰ï¼Œéœ€è¦ä»å¤´å¼€å§‹

### æ¢å¤è®­ç»ƒ
```bash
./resume_training.sh
```
**è¯´æ˜**:
- ä¼šåœ¨åå°å¯åŠ¨è®­ç»ƒ
- æ—¥å¿—ä¿å­˜åˆ° `training.log`
- ä½¿ç”¨ `tail -f training.log` æŸ¥çœ‹å®æ—¶æ—¥å¿—

### æŸ¥çœ‹è®­ç»ƒæ—¥å¿—
```bash
# å®æ—¶æŸ¥çœ‹æ—¥å¿—
tail -f training.log

# æŸ¥çœ‹æœ€å 50 è¡Œ
tail -50 training.log

# æœç´¢é”™è¯¯
grep -i error training.log
```

### æŸ¥çœ‹è®­ç»ƒæ—¥å¿—ï¼ˆå‰å°è¿è¡Œæ—¶ï¼‰
è®­ç»ƒè¿‡ç¨‹ä¼šå®æ—¶æ˜¾ç¤ºï¼š
- è®­ç»ƒæ­¥æ•°
- æŸå¤±å€¼ (Loss)
- å­¦ä¹ ç‡
- è®­ç»ƒé€Ÿåº¦

### æ£€æŸ¥ Checkpoints
æ¨¡å‹ä¼šæ¯ 500 æ­¥ä¿å­˜ä¸€æ¬¡ checkpointï¼š
```bash
ls -lh css_assistant_model/checkpoint-*
```

## ğŸ“ è¾“å‡ºæ–‡ä»¶

è®­ç»ƒå®Œæˆåï¼Œæ¨¡å‹å°†ä¿å­˜åœ¨ï¼š
```
css_assistant_model/
â”œâ”€â”€ adapter_config.json      # LoRA é…ç½®
â”œâ”€â”€ adapter_model.safetensors # LoRA æƒé‡
â”œâ”€â”€ tokenizer_config.json    # åˆ†è¯å™¨é…ç½®
â”œâ”€â”€ tokenizer.json           # åˆ†è¯å™¨
â””â”€â”€ checkpoint-*/            # è®­ç»ƒæ£€æŸ¥ç‚¹
```

## â±ï¸ é¢„è®¡è®­ç»ƒæ—¶é—´

- **æ€»æ­¥æ•°**: 1,953 æ­¥ (10,406 æ ·æœ¬ Ã· 16 æœ‰æ•ˆæ‰¹æ¬¡ Ã— 3 è½®)
- **é¢„è®¡æ—¶é—´**: 
  - M1 Pro (32GB): çº¦ 2-4 å°æ—¶
  - å…·ä½“æ—¶é—´å–å†³äº CPU/GPU æ€§èƒ½

## ğŸ¯ è®­ç»ƒå®Œæˆå

### 1. æµ‹è¯•æ¨¡å‹
```python
from transformers import AutoTokenizer, AutoModelForCausalLM
from peft import PeftModel

# åŠ è½½åŸºåº§æ¨¡å‹
base_model = AutoModelForCausalLM.from_pretrained("Qwen/Qwen2.5-3B-Instruct")
tokenizer = AutoTokenizer.from_pretrained("Qwen/Qwen2.5-3B-Instruct")

# åŠ è½½ LoRA æƒé‡
model = PeftModel.from_pretrained(base_model, "css_assistant_model")

# æµ‹è¯•
prompt = "ç”Ÿæˆä¸€ä¸ªå±…ä¸­çš„çº¢è‰²æ–‡å­—çš„ CSS ç±»"
inputs = tokenizer(prompt, return_tensors="pt")
outputs = model.generate(**inputs, max_length=100)
print(tokenizer.decode(outputs[0]))
```

### 2. åˆå¹¶æ¨¡å‹ï¼ˆå¯é€‰ï¼‰
```python
# å°† LoRA æƒé‡åˆå¹¶åˆ°åŸºåº§æ¨¡å‹
merged_model = model.merge_and_unload()
merged_model.save_pretrained("css_assistant_merged")
```

### 3. éƒ¨ç½²æ¨¡å‹
- ä½¿ç”¨ FastAPI/Flask åˆ›å»º API æœåŠ¡
- é›†æˆåˆ°ç°æœ‰é¡¹ç›®ä¸­
- éƒ¨ç½²åˆ°äº‘æœåŠ¡å™¨

## ğŸ“ æ³¨æ„äº‹é¡¹

1. **ä¸è¦ä¸­æ–­è®­ç»ƒ**: è®­ç»ƒè¿‡ç¨‹ä¸­è¯·ä¿æŒç”µè„‘è¿è¡Œ
2. **å®šæœŸæ£€æŸ¥**: ä½¿ç”¨ `monitor_training.sh` æŸ¥çœ‹è¿›åº¦
3. **ç£ç›˜ç©ºé—´**: ç¡®ä¿æœ‰è¶³å¤Ÿç©ºé—´ä¿å­˜ checkpointsï¼ˆçº¦ 5-10GBï¼‰
4. **å†…å­˜ä½¿ç”¨**: è®­ç»ƒä¼šå ç”¨çº¦ 8-16GB å†…å­˜

## ğŸ› æ•…éšœæ’é™¤

### è®­ç»ƒä¸­æ–­
å¦‚æœè®­ç»ƒæ„å¤–ä¸­æ–­ï¼Œå¯ä»¥ä»æœ€æ–°çš„ checkpoint æ¢å¤ï¼š
```bash
# æŸ¥æ‰¾æœ€æ–°çš„ checkpoint
ls -lt css_assistant_model/checkpoint-* | head -1

# ä¿®æ”¹è®­ç»ƒè„šæœ¬ï¼Œæ·»åŠ  resume_from_checkpoint å‚æ•°
```

### å†…å­˜ä¸è¶³
å¦‚æœé‡åˆ°å†…å­˜ä¸è¶³ï¼š
1. å‡å°æ‰¹æ¬¡å¤§å°ï¼ˆä¿®æ”¹ `BATCH_SIZE`ï¼‰
2. å¢åŠ æ¢¯åº¦ç´¯ç§¯æ­¥æ•°ï¼ˆä¿®æ”¹ `GRADIENT_ACCUMULATION_STEPS`ï¼‰
3. å‡å°æœ€å¤§åºåˆ—é•¿åº¦ï¼ˆä¿®æ”¹ `MAX_LENGTH`ï¼‰

### è®­ç»ƒé€Ÿåº¦æ…¢
- M1/M2 Mac ä¼šä½¿ç”¨ MPS åŠ é€Ÿ
- å¦‚æœå¤ªæ…¢ï¼Œè€ƒè™‘ä½¿ç”¨äº‘ GPUï¼ˆå¦‚ Colab, AWS, é˜¿é‡Œäº‘ï¼‰

## ğŸ“ æ”¯æŒ

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æ£€æŸ¥ï¼š
1. è®­ç»ƒæ—¥å¿—è¾“å‡º
2. `css_assistant_model/` ç›®å½•å†…å®¹
3. ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µï¼ˆå†…å­˜ã€CPUï¼‰
