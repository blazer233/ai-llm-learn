#!/usr/bin/env python3
"""
CSS ç±»ååŠ©æ‰‹ - å‘½ä»¤è¡Œå¾®è°ƒè„šæœ¬
ä½¿ç”¨ Qwen2.5-3B-Instruct + QLoRA
"""

import os
import sys

# æ·»åŠ  LLaMA-Factory åˆ°è·¯å¾„
sys.path.insert(0, "/Users/songyanchao/Desktop/thing/zhishi/finetune/LLaMA-Factory/src")

from llamafactory.train.tuner import run_exp

def main():
    # è®­ç»ƒå‚æ•°
    args = {
        # æ¨¡å‹é…ç½®
        "model_name_or_path": "Qwen/Qwen2.5-3B-Instruct",
        "trust_remote_code": True,
        
        # æ•°æ®é…ç½®
        "dataset": "css_assistant",
        "template": "qwen",
        "cutoff_len": 512,
        "max_samples": 10406,
        "overwrite_cache": True,
        "preprocessing_num_workers": 4,
        
        # LoRA é…ç½®
        "finetuning_type": "lora",
        "lora_rank": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.05,
        "lora_target": "all",
        
        # è®­ç»ƒå‚æ•°
        "stage": "sft",
        "do_train": True,
        "output_dir": "/Users/songyanchao/Desktop/thing/zhishi/finetune/output_model",
        "overwrite_output_dir": True,
        
        # ä¼˜åŒ–å™¨é…ç½®
        "per_device_train_batch_size": 2,
        "gradient_accumulation_steps": 4,
        "learning_rate": 5e-5,
        "num_train_epochs": 3,
        "lr_scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        
        # ä¿å­˜é…ç½®
        "save_steps": 500,
        "logging_steps": 10,
        "save_total_limit": 3,
        
        # å…¶ä»–é…ç½®
        "fp16": False,
        "bf16": True,
        "ddp_timeout": 180000000,
        "report_to": "none",
    }
    
    print("=" * 60)
    print("ğŸš€ å¼€å§‹å¾®è°ƒ CSS ç±»ååŠ©æ‰‹")
    print("=" * 60)
    print(f"ğŸ“¦ åŸºåº§æ¨¡å‹: {args['model_name_or_path']}")
    print(f"ğŸ“Š æ•°æ®é›†: {args['dataset']} ({args['max_samples']} æ¡)")
    print(f"ğŸ”§ å¾®è°ƒæ–¹æ³•: LoRA (rank={args['lora_rank']})")
    print(f"ğŸ“ˆ è®­ç»ƒè½®æ•°: {args['num_train_epochs']}")
    print(f"ğŸ’¾ è¾“å‡ºç›®å½•: {args['output_dir']}")
    print("=" * 60)
    print()
    
    # å¼€å§‹è®­ç»ƒ
    try:
        run_exp(args)
        print("\n" + "=" * 60)
        print("âœ… è®­ç»ƒå®Œæˆï¼")
        print(f"ğŸ“ æ¨¡å‹ä¿å­˜åœ¨: {args['output_dir']}")
        print("=" * 60)
    except Exception as e:
        print(f"\nâŒ è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
